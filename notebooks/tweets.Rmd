---
title: "tweets"
author: "Frank Dreyer"
date: "12 6 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rtweet)
library(academictwitteR)
library(anytime)

data_dir <- "data"
tweet_dir <- data_dir %>% paste("tweets", sep = "/")
```


```{r read_nba_data}
player_metadata <- paste(data_dir,"player-metadata.csv", sep ="/") %>% read_csv()
player_game_stats <- paste(data_dir,"player-game-stats.csv", sep ="/") %>% read_csv()
game_metadata <- paste(data_dir,"game-metadata.csv", sep ="/") %>% read_csv()
player_season_stats <- paste(data_dir,"player-season-stats.csv", sep ="/") %>% read_csv()
```


```{r select_relevant_players}

relevant_players <- player_season_stats %>% 
  
  # Players who played actively (>= 80% of games) for the same team between 2016-2019 (3 seasons)
  filter(Season %in% c("2016-17", "2017-18", "2018-19")) %>% 
  filter(SeasonType == "Regular Season") %>% 
  group_by(BBRef_Player_ID) %>% 
  filter(n() == 3) %>% 
  summarise(
    team_cnt = length(unique(Team)),
    game_cnt = sum(G)
  ) %>% 
  filter(team_cnt == 1) %>% 
  filter(game_cnt >= 0.8 * 82 * 3) %>% 
  select(BBRef_Player_ID) %>% 
  
  # Players whose BPM varied by a standard deviation of at least 8
  inner_join(player_game_stats) %>% 
  group_by(BBRef_Player_ID) %>% 
  summarise(sd_BPM = sd(BPM, na.rm = TRUE)) %>% 
  filter(sd_BPM >= 8) %>% 
  select(BBRef_Player_ID) %>% 
  
  # Players with at least 1000 followers
  inner_join(player_metadata) %>% 
  pmap_dfr(function(...){
    relevant_player <- tibble(...)
    twitter_meta <- relevant_player$Twitter %>% 
      lookup_users() %>% 
      select(c("screen_name", "followers_count"))
    inner_join(relevant_player, twitter_meta, by = c("Twitter" = "screen_name"))
  }) %>% filter(followers_count >= 1000) %>% 
  select(player_metadata %>% names())
  
  
relevant_players
```


```{r select_relevant_player_stats}
relevant_player_stats <- relevant_players %>% 
  inner_join(player_game_stats) %>% 
  filter(! is.na(MP)) %>% 
  inner_join(game_metadata) %>% 
  filter(Season %in% c("2017-18", "2018-19"))

relevant_player_stats
```


```{r extract_and_save_tweets}
token <- "" # Insert bearer-token here
time_window <- 48
tweet_cols <- c("BBRef_Player_ID", "BBRef_Game_ID", "id", "text", "created_at", "retweet_count", "reply_count", "like_count", "quote_count")
alrdy_proc_plyrs <- list.files(tweet_dir) %>% map_chr(~ str_remove(.x, "\\.csv$"))


relevant_player_stats %>% 
  filter(! Twitter %in% c(alrdy_proc_plyrs)) %>% 
  mutate(EndTweet = DateTime - lubridate::dminutes(45)) %>% 
  mutate(StartTweet = EndTweet - lubridate::dhours(time_window)) %>% 
  
  # Save tweets player-wise
  group_by(BBRef_Player_ID) %>% 
  group_walk(~ {
    tweets <- .x %>% pmap_dfr(function(...) {
      player_game_data <- tibble(...)
      
      start_tweets = player_game_data$StartTweet %>% iso8601() %>% paste0("Z")
      end_tweets = player_game_data$EndTweet %>% iso8601() %>% paste0("Z")
      
      twts <- tibble()
      
      tryCatch({
          twts <- get_all_tweets(
            query = player_game_data$Twitter,
            start_tweets = start_tweets,
            end_tweets = end_tweets,
            is_retweet = FALSE,
            lang = "en",
            bearer_token = token
          ) %>% 
            mutate(BBRef_Player_ID = player_game_data$BBRef_Player_ID) %>% 
            mutate(BBRef_Game_ID = player_game_data$BBRef_Game_ID)
        }, error = function(e) {
          # For Status Code 503
          print("Error loading tweets for the following game: ")
          print(player_game_data %>% select(c(Twitter, BBRef_Game_ID, DateTime, StartTweet, EndTweet)))
        }, finally = {
          return(twts)
        }
      )
      
    }) %>% 
      mutate(retweet_count = public_metrics$retweet_count) %>% 
      mutate(reply_count = public_metrics$reply_count) %>% 
      mutate(like_count = public_metrics$like_count) %>% 
      mutate(quote_count = public_metrics$quote_count) %>% 
      select(tweet_cols)
    
    file_name <- .x$Twitter %>% unique() %>% paste0(".csv")
    file_path <- tweet_dir %>% paste(file_name, sep = "/")
    
    tweets %>% write_csv(file_path)
  })
```


```{r load_tweets}
tweets <- list.files(tweet_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

tweets <- player_metadata %>% inner_join(tweets)
tweets
```

