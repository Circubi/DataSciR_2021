---
title: "Exploratory Data Analysis (EDA)"
author: "Frank Dreyer"
date: "19 6 2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidytext)
library(ggwordcloud)
library(stringr)
library(ggpubr)

knitr::opts_chunk$set(
  echo = FALSE, 
  eval = FALSE, 
  message = FALSE,
  warning = FALSE, 
  fig.show = "asis"
)

data_dir <- "../data"
tweets_dir <- data_dir %>% paste("tweets", sep = "/")
sentiments_dir <- data_dir %>% paste("sentiments", sep = "/")
```


```{r load_nba_stats, eval = TRUE}
player_metadata <- paste(data_dir,"player-metadata.csv", sep ="/") %>% read_csv()
player_game_stats <- paste(data_dir,"player-game-stats.csv", sep ="/") %>% read_csv()
game_metadata <- paste(data_dir,"game-metadata.csv", sep ="/") %>% read_csv()
player_season_stats <- paste(data_dir,"player-season-stats.csv", sep ="/") %>% read_csv()
```


```{r load_tweets, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

prep_tweets <- data_dir %>% 
  paste("prep-tweets.csv", sep = "/") %>% 
  read_csv()
```


```{r load_sentiments, eval = TRUE}
sentiment_names <- c("bing", "syuzhet", "jockers_rinker", "afinn", "nrc", "novak_emoji")

sentiments <- sentiment_names %>% 
  map_dfr(~ {
    sentiment_name <- .x
    
    sentiment_file <- sentiments_dir %>% 
      paste(sentiment_name, sep = "/") %>% 
      paste0(".csv") %>% 
      str_replace("_", "-")
    
    sentiments_tmp <- read_csv(sentiment_file) %>% 
      mutate(positive_sentiment = if_else(ave_sentiment >= 0, TRUE, FALSE)) %>% 
      mutate(sentiment_lexicon = sentiment_name)
      
  })
```

## Comparability of the Sentiment Lexicons

In the beginning we wanted to assess if the sentiment scores the different sentiment lexicons provided for tweets were actually comparable. For that purpose we computed the Spearman rank correlation coefficient between tweet sentiment scores provided by each pair of sentiment lexicons to assess whether the ranking of the tweets according to one sentiment lexicon agrees with the ranking of the tweets according to another sentiment lexicon. 

```{r compute_sentiment_consensus_spearman, eval = TRUE}
sentiment_lexicons <- sentiments$sentiment_lexicon %>% unique()

# Create cross product of sentiment_lexicon with itself
sentiment_lexicons_a <- sentiment_lexicons %>% 
  rep(each = length(sentiment_lexicons))
sentiment_lexicons_b <- sentiment_lexicons %>% 
  rep(times = length(sentiment_lexicons))

# For each pair of sentiment lexicons compute Kendall rank correlation coefficient
sentiment_lexicon_consensus <- map2_dfr(sentiment_lexicons_a, sentiment_lexicons_b, ~ {
  
  sentiments_a <- sentiments %>% 
    filter(sentiment_lexicon == .x) %>% 
    mutate(ave_sentiment_a = ave_sentiment) %>% 
    select(id, ave_sentiment_a) 
  
  sentiments_b <- sentiments %>% 
    filter(sentiment_lexicon == .y) %>%
    mutate(ave_sentiment_b = ave_sentiment) %>% 
    select(id, ave_sentiment_b)
  
  inner_join(sentiments_a, sentiments_b) %>% 
    mutate(sentiment_lexicon_a = .x) %>% 
    mutate(sentiment_lexicon_b = .y) %>%  
    group_by(sentiment_lexicon_a, sentiment_lexicon_b) %>% 
    summarise(consensus = cor(ave_sentiment_a, ave_sentiment_b, method = "spearman", use = "complete.obs")) %>% 
    ungroup()
  
})
```

We then plotted the results into a heatmap:

```{r plot_sentiment_consensus, eval = TRUE}
sentiment_lexicon_consensus %>% 
  ggplot(mapping = aes(x = sentiment_lexicon_a, y = sentiment_lexicon_b, fill = consensus)) +
    geom_tile() +
    colorspace::scale_fill_continuous_sequential("Purples") +
    theme_minimal() + 
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank()
    )
```

## Computing Sentiment Aggregates

Since the sentiment scores were computed on a per-tweet basis we first had to aggregate the sentiment scores accordingly in order to capture the overall social media vibe players were receiving before games in a single number. For that purpose we considered  the sentiment scores of all tweets a respective player received in a 24-hour window before a respective game and aggregated them as follows:  

* The average of the sentiment scores (mean). 
* The average of the sentiment scores weighted by the retweet count of the associated tweet (weighted mean). 
* The proportion of tweets with a negative associated sentiment score (< 0).


```{r compute_sentiment_aggregates_24h_before_games, eval = TRUE}
tweets_24h_before_games <- player_game_stats %>%
  inner_join(game_metadata) %>% 
  inner_join(tweets) %>% 
  mutate(h_timediff_game = as.double(DateTime - created_at, units = "hours")) %>% 
  select(c(names(tweets), h_timediff_game))  %>%
  filter(h_timediff_game <= 24)

sentiment_aggregates_24h_before_games <- tweets_24h_before_games %>% 
  inner_join(sentiments) %>% 
  group_by(BBRef_Player_ID, BBRef_Game_ID, sentiment_lexicon) %>% 
  summarise(
    avg_sentiment = mean(ave_sentiment),
    avg_sentiment_retweet_cnt_weighted = weighted.mean(ave_sentiment, retweet_count),
    rel_freq_negative = sum(!positive_sentiment) / n()
  ) 
```

The following table shows an excerpt of the per-game computed sentiment aggregates for the different sentiment lexicons: 

```{r display_sentiment_aggregates_24h_before_games, eval = TRUE, message = TRUE}
sentiment_aggregates_24h_before_games
```

## Univariate Distribution Analysis

At this point we had all the necessary data to analyze the association between the aggregated sentiment scores of tweets the players received within 24 hours before games and their performance within the games. 

Before analyzing these bivariate relationships however we first wanted to get a general idea how the individual variables were distributed. 

### Distribution of the Sentiment Aggregates

Plotting the density curves for the unweighted average sentiment scores for the different sentiment lexicons and players revealed the following picture: 

```{r plot_density_curves_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Density Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Looking at the individual density curves we observed that the distributions of the average sentiment scores rougly fit the bell curve of a Normal distribution despite a few exceptions (esp. for the averaged sentiments for the emoji sentiment lexicon by Novak). 

To check our normality assumption we also constructed Q-Q plots for the unweighted average sentiment scores: 

```{r plot_qq_plot_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

The Q-Q plots confirmed our assumption of normality, since despite some curve offs at the extremities (some observed extremes were more extreme than expected), most of the observed quantiles matched the expected quantiles of the fitted Normal distribution. 

A similar picture could be observed for the average weighted sentiment scores (weighted by their associated retweet count) as the following equivalent grid of Q-Q plots shows:

```{r plot_qq_plot_avg_weighted_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment_retweet_cnt_weighted)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were\nreceiving within 24 Hours before Games weighted by their Retweet Count", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons  2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
```

The distributions for the negative tweet proportions mostly did not follow a Normal distribution and were strongly right skewed however. That intuitively made sense since in most of the cases players only received a small proportion of tweets with a negative sentiment which leads to the right skewness of the distribution (also because proportions cannot go below 0). The following grid of density plots emphasize that circumstance:

```{r plot_density_curves_weighted_rel_freq_negative, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free")+ 
    labs(
      title = "Density Plots of the Proportion of Tweets with a negative Sentiment Players were receiving within 24 Hours before Games",
      subtitle = "For different Players and Sentiments Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Proportion of Negative Tweets", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

### Distribution of the Box Plus/Minus Performance Indicator

Besides the sentiment aggregates we also studied how the BPM perfomance indicator values are distributed for the different players. Similar to the unweighted and weighted sentiment averages before, BPM was also normally distributed as the following grid of Q-Q plots indicates: 

```{r plot_qq_plot_BPM, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  mutate(variable = "BPM") %>% 
  distinct(Player, BBRef_Game_ID, BPM, variable) %>% 
  ggplot(mapping = aes(sample = BPM)) + 
    geom_qq(alpha = 0.4) + 
    geom_qq_line() + 
    facet_grid(Player ~ variable, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Knowing that the BPM values were normally distributed for the different players it was sufficient to simply construct boxplots for the performance indicator to get a sense how the individual players performed in general in the two considered seasons and how their performance fluctuated. 

```{r plot-boxplot-BPM, eval = TRUE}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  distinct(Player, BBRef_Game_ID, BPM) %>% 
  ggplot(mapping = aes(x = reorder(Player, BPM, na.rm = TRUE), y = BPM)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(
      title = "Boxplots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.y = element_blank()
    ) 
```


## Bivariate Distribution and Correlation Analysis

After having observed the univariate distributions of the variables that were of importance for this analysis we now wanted to assess whether there is a relationship between the individual sentiment aggregates and the BPM values for any of the individual players and sentiment lexicons. 

### Relationship between the Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

We began by having a closer look at the relationship between the unweighted sentiment average and the BPM performance indicator. For that purpose we created a grid of scatterplots for each player and sentiment lexicon combination and fitted a simple linear regression line through each of the resulting point clouds. Additionally, to measure the strength and direction of a potential bivariate linear relationships, we made use of the `ggpubr`-library by adding the corresponding Pearson correlation coefficient *r* and its associated *p*-value (using a T-test statistic with n-2 degrees of freedom) to each scatterplot. It should be noted here that the Pearson correlation coefficient was applicable since both variables were normally distributed as indicated before. Furthermore, we added the *p*-value to measure how significant the corresponding Pearson correlation coefficient deviated from zero (no correlation / linear relationship). The resulting plot is represented below.

```{r plot_relationship_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Average Sentiment of Tweets Players received\nwithin 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

As one can see, the points of the different scatterplots appeared rather scattered and for the different sentiment lexicons and players there was neither a strong nor direclty visible (linear) relationship between the average tweet sentiment and the BPM performance indicator. Even though some of the linear regression lines suggested a correlation, the correlations themselves were rather weak or even neglectable as indicated by the respective Pearson correlation coefficients *r* that were relatively small (mostly less than 0.1). Additionally most of the *p*-values of the associated Pearson correlation coefficients were rather high which suggested that the observed strength of the correlations were not significantly different from 0 (and might have appeared due to random chance). 

Nevertheless, there were also some counter examples where the Pearson correlation coefficient appeared rather significant. The player Jaylen Brown for example showed a positive correlation for the Afinn lexicon with a *p*-value below 0.05. However, since the correlations were rather weak, not significant and somehow contradicting for other sentiment lexicons (compare that the correlation was negative for the nrc lexicon), it is debatable if the positive correlation is generalizable for the entire population or even the single player alone. 

Due to these reasons we had to conclude that there is no evidence of a significantly strong linear correlation between the average sentiment of tweets players receive within 24 hours before games and their performance within the games. 

There was however another interesting observation the scatterplots revealed, namely the prominent outliers. For almost every player there was at least one game day in which the average tweet sentiment was vastly more positive compared to other days. Additionally there were some players with game days associated with an extremely negative average tweet sentiment in comparison to other days. To investigate these outliers more closely we created two word clouds for each player, one for the smallest average tweet sentiment the player received and one for the highest. We used the tweet sentiments created from the Jockers-Rinker lexicon for this purpose. 

[TODO] word clouds

```{r plot_word_clouds_extreme_sentiments, eval = TRUE, fig.width = 10, fig.height = 35}
extreme_neg_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, - avg_sentiment) %>% 
  mutate(extreme_type = "Most Negative")

extreme_pos_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, avg_sentiment) %>% 
  mutate(extreme_type = "Most Positive")

word_frequencies <- bind_rows(extreme_neg_sentiments, extreme_pos_sentiments) %>% 
  inner_join(player_metadata) %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  mutate(prep_text = str_remove_all(prep_text, "[:digit:]")) %>% 
  group_by(Player, extreme_type) %>% 
  unnest_tokens(word, prep_text) %>% 
  anti_join(stop_words) %>%
  group_by(Player, extreme_type, word) %>% 
  summarise(freq = n()) 

total_words <- word_frequencies %>% 
  group_by(Player, extreme_type) %>% 
  summarise(total = sum(freq)) 

rel_word_frequencies <- word_frequencies %>% 
  inner_join(total_words) %>% 
  mutate(rel_freq = freq / total)

rel_word_frequencies %>% 
  arrange(desc(rel_freq)) %>% 
  group_by(Player, extreme_type) %>% 
  slice_head(n = 50) %>% 
  ggplot(mapping = aes(label = word, size = rel_freq)) + 
    geom_text_wordcloud_area() + 
    scale_size_area(max_size = 20) + 
    facet_grid(Player ~ extreme_type) +
    theme_minimal()
```


### Relationship between the Weighted Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

One might argue that ... [TODO]

```{r plot_relationship_weighted_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment_retweet_cnt_weighted, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Retweet Count Weighted Average Sentiment of Tweets Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Retweet Count Weighted Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

There were however also some exceptions. For Josh Richardson the Pearson correlation coefficients appeared to be rather significant with *p*-values less than 0.1 for the different sentiment lexicons (except for the emoji lexicon by Novak). Despite the fact that these correlations were all positive for this player, they were still quite weak however, with a maximum Pearson correlation coefficient of 0.29 for the Jockers-Rinker sentiment lexicon. 

### Relationship between the Proportion of Negative Tweets and the BPM Performance Indicator

[TODO]

used Kendall instead of Pearson due since proportion was not normally distributed and required a non-parametric coefficient 

```{r plot_relationship_rel_freq_negative_tweets_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "kendall", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Proportion of Tweets with a Negative Sentiment Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Relative Frequency of Negative Tweets",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

### Time Dependent Relationship between the Average Tweet Sentiments and the BPM Performance Indicator

[TODO]

```{r season_18_19_trend_BPM_vs_jockers_rinker, eval = FALSE, message = TRUE, fig.width = 10, fig.height = 80}
scaling_coef <- 60

player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  filter(SeasonType == "Regular Season") %>% 
  filter(Season %in% c("2018-19")) %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  rename(jockers_rinker = avg_sentiment) %>% 
  ggplot(mapping = aes(x = Date)) +
  
    geom_smooth(mapping = aes(y = BPM), se = FALSE, color = "blue") + 
    geom_line(mapping = aes(y = BPM), color = "blue", alpha = 0.2) + 
  
    geom_smooth(mapping = aes(y = jockers_rinker * scaling_coef), se = FALSE, color = "red") +
    geom_line(mapping = aes(y = jockers_rinker * scaling_coef), color = "red", alpha = 0.2) + 
  
    facet_wrap(~ Player, ncol = 1) +
  
    scale_y_continuous( 
      name = "BPM",
      sec.axis = sec_axis(~./scaling_coef, name = "Jockers/Rinker")
    ) + 
    coord_cartesian(ylim = c(-10,20)) + 
    theme_minimal() + 
    theme(
      axis.title.y = element_text(color = "blue"),
      axis.title.y.right = element_text(color = "red")
    )
```


```{r compute_sentiment_consensus_binary, eval = FALSE}
sentiment_lexicons <- sentiments$sentiment_lexicon %>% unique()

# Create cross product of sentiment_lexicon with itself
sentiment_lexicons_a <- sentiment_lexicons %>% 
  rep(each = length(sentiment_lexicons))
sentiment_lexicons_b <- sentiment_lexicons %>% 
  rep(times = length(sentiment_lexicons))

sentiment_lexicon_consensus <- map2_dfr(sentiment_lexicons_a, sentiment_lexicons_b, ~ {
  
  sentiments_a <- sentiments %>% 
    filter(sentiment_lexicon == .x) %>% 
    select(id, positive_sentiment) %>% 
    filter(! is.na(positive_sentiment)) %>% 
    rename(positive_lexicon_a = positive_sentiment)
  
  sentiments_b <- sentiments %>% 
    filter(sentiment_lexicon == .y) %>% 
    select(id, positive_sentiment) %>% 
    filter(! is.na(positive_sentiment)) %>% 
    rename(positive_lexicon_b = positive_sentiment)
  
  inner_join(sentiments_a, sentiments_b) %>% 
    mutate(sentiment_lexicon_a = .x) %>% 
    mutate(sentiment_lexicon_b = .y) %>% 
    mutate(consensus = positive_lexicon_a == positive_lexicon_b) %>% 
    group_by(sentiment_lexicon_a, sentiment_lexicon_b) %>% 
    summarise(consensus = sum(consensus) / n()) %>% 
    ungroup()
  
})
```



Observation: On extremely positive sentiment values (outliers) the player had birthday. 

```{r birthday_outliers, eval = TRUE, message = FALSE}
sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "nrc") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, avg_sentiment) %>% 
  select(c(BBRef_Player_ID, BBRef_Game_ID)) %>% 
  inner_join(player_metadata) %>% 
  inner_join(tweets) %>% 
  filter(Player == "Draymond Green") %>% 
  select(c(Player, created_at, text))
```

