---
title: "twitter_text_processing"
output: html_document
---
```{r packages, message = FALSE}
library(rvest)
library(stringr)
library(rlist)
library(tidyverse)
library(jsonlite)
library(tokenizers)
library(dplyr)
```

```{r load_data}
mainDir <- "./data/" 
tweets <- list.load(file = paste(mainDir, "/tweets/tweets_list.RData",sep=""))
```

```{r transform_text}
# transform twitter text emojis to unicode
tweets_text <- tweets %>%
  map_dfr(~ bind_rows(.x)) %>%
  select(text, Player, DateTime, GameId)

tweets_text <- map(tweets_text$text, format_) %>%
  list.rbind() %>%
  as.data.frame() %>%
  set_names("unicode_text") %>%
  cbind(tweets_text)

format_ <- function(text){
  text_unicode <- iconv(text, "UTF-8", "ASCII", "Unicode")
    text_unicode <- text_unicode %>%
      str_replace_all("<"," <")
  return(text_unicode)
} 
```

```{r emoji_sentiment}
# get the emoji unicode and sentiment score
# http://kt.ijs.si/data/Emoji_sentiment_ranking/index.html
content <- read_html("http://kt.ijs.si/data/Emoji_sentiment_ranking/index.html")

table <- content %>%
  html_table() 

emoji_sentiment_score <- table[[1]] %>%
  select(Char, `Sentiment score[-1...+1]`) %>%
  mutate(Char = iconv(Char, "UTF-8", "ASCII", "Unicode")) 

# get the emotions for emojis in unicode
emoji_emotion <- fromJSON(paste(mainDir,"emoji_5sentiment_dictionary.json",sep ="")) %>%
  bind_rows(.id = "id") %>%
  mutate(id = iconv(id, "UTF-8", "ASCII", "Unicode"))

# final emoji sentiment lexicon
emoji <- emoji_sentiment_score %>%
  full_join(emoji_emotion, by = c("Char" = "id"))
```

```{r tokenization}
# funktion die für jeden spieler die wörter tokenized und game_id ,(zeit), name mitspeichert

}


```

