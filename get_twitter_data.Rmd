---
title: "get_twitter_data"
output: pdf_document
---

```{r packages, message = FALSE}
library(readr)
library(anytime)
library(lubridate)
library(academictwitteR)
library(tidyverse)
library(jsonlite)
library(rlist)
```

```{r data and specify directory}
# set main directory to save data to
mainDir <- "~/Documents/GitHub/DataSciR_2021/data/"

player_metadata <- read_csv(paste(mainDir,"player-metadata.csv", sep =""))
player_game_stats <- read_csv(paste(mainDir,"player-game-stats.csv", sep =""))
game_metadata <- read_csv(paste(mainDir,"game-metadata.csv", sep =""))
player_season_stats <- read_csv(paste(mainDir,"player-season-stats.csv", sep =""))

# create directories if they don't exist
if (!dir.exists(paste(mainDir, "tweets/", sep =""))) {dir.create(paste(mainDir, "tweets/", sep =""))}
if (!dir.exists(paste(mainDir, "tweets/json/", sep =""))) {dir.create(paste(mainDir, "tweets/json/", sep =""))}
```


```{r select relevant players} 
# players who played for the same team during the seasons 2016/17/18/19
player_season <- player_season_stats %>%
  filter(Season == "2016-17" |Season == "2017-18" | Season == "2018-19") %>%
  filter(SeasonType == "Regular Season") %>%
  group_by(BBRef_Player_ID) %>%
  filter(n() == 3) %>%
  summarize(m = length(unique(Team))) %>%
  arrange(m) %>%
  filter(m == 1) %>%
  select(BBRef_Player_ID) %>%
  inner_join(player_game_stats)

# sd of players using BPM as metric  
player_sd <- player_season %>%
  group_by(BBRef_Player_ID) %>%
  summarize(sd_bpm = sd(BPM,na.rm = TRUE)) %>%
  left_join(player_metadata)

# combine with twitter profile data 
player_twitter_sd <- lookup_users(player_sd %>% select(Twitter) %>% pull()) %>%
  select(followers_count, statuses_count, favourites_count, screen_name) %>%
  inner_join(player_sd, by = c("screen_name" = "Twitter"))

# list of players to choose from
final_player_list <- player_season_stats %>%
  filter(Season == "2016-17" |Season == "2017-18" | Season == "2018-19") %>%
  filter(SeasonType == "Regular Season") %>%
  group_by(BBRef_Player_ID) %>%
  filter(n() == 3) %>%
  summarize(m = length(unique(Team))) %>%
  filter(m == 1) %>%
  inner_join(player_season_stats) %>%
  filter(Season == "2016-17" |Season == "2017-18" | Season == "2018-19") %>%
  filter(SeasonType == "Regular Season") %>%
  group_by(BBRef_Player_ID) %>%
  summarize(game_count = sum(G)) %>%
  inner_join(player_twitter_sd) %>%
  left_join(player_metadata)
```

```{r combine player and game datetimes}
# select the relevant game ids, datetimes and player names
player_game <- player_game_stats %>%
  filter(BBRef_Player_ID %in% final_player_list$BBRef_Player_ID) %>%
  filter(Season == "2017-18" | Season == "2018-19") %>%
  select(BBRef_Player_ID, BBRef_Game_ID) %>%
  left_join(final_player_list %>% select(BBRef_Player_ID, Twitter)) 

#final dataset to use in the twitter api
game_time <- game_metadata %>%
  select(BBRef_Game_ID, DateTime) %>%
  inner_join(player_game) 
```

```{r save_tweets function}
# function to get the tweets for every unique game,player combination
save_tweets <- function(player, time){
  tweets <- get_all_tweets( 
    player,
    (time - hours(48)) %>% iso8601() %>% paste("Z", sep = ""), # starttime
    (time - minutes(45)) %>% iso8601() %>% paste("Z", sep = ""), # endtime
    lang = "en",
    bearer_token = bearer_token)
  
  tweets <- tweets %>%
    mutate(Player = player, DateTime = time)
  
  write_json(tweets, path = paste(mainDir, "tweets/json/", player,"_", time %>% iso8601(), ".json",sep=""))
}
```

```{r bind_tweet_jsons function}
# change the bind_tweet_json function from academictwitteR to use a different pattern
bind_tweet_jsons <- function(player, data_path = paste(mainDir, "tweets/json/",sep="")) {
  if(substr(data_path, nchar(data_path), nchar(data_path)) != "/"){
    data_path <- paste0(data_path,"/")
  }
  # parse and bind
  files <-
    list.files(
      path = file.path(data_path),
      pattern = paste("^",player,sep=""),
      recursive = T,
      include.dirs = T
    )
  
  if(length(files)<1){
    stop(paste("There are no files matching the pattern ‘",player, "_‘", " in the specified directory.", sep = ""))
  }
  
  files <- paste(data_path, files, sep = "")
  
  pb = utils::txtProgressBar(min = 0,
                             max = length(files),
                             initial = 0)
  
  json.df.all <- data.frame()
  for (i in seq_along(files)) {
    filename = files[[i]]
    json.df <- jsonlite::read_json(filename, simplifyVector = TRUE)
    json.df.all <- dplyr::bind_rows(json.df.all, json.df)
    utils::setTxtProgressBar(pb, i)
  }
  cat("\n")
  return(json.df.all)
}
```

```{r save tweets}
# actual call to save all tweets 
map2(game_time$Twitter, game_time$DateTime, save_tweets) # saves all tweets in json files in /data/tweets/json/

# named list to save tweets by player
map(game_time$Twitter, bind_tweet_jsons) %>%
  set_names(game_time$Twitter %>% unique()) %>%
  list.save(file = paste(mainDir, "/tweets/tweets_list.RData",sep=""))
```
